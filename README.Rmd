<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%",
  dpi=300,fig.width=7,
  fig.keep="all"
)

LOCAL <- identical(Sys.getenv("LOCAL"), "TRUE")

knitr::opts_chunk$set(purl = LOCAL)
```

# SelectBoost.beta <img src="man/figures/logo.svg" align="right" width="200"/>

<!-- badges: start -->
<!-- [![DOI](https://img.shields.io/badge/doi-10.32614/CRAN.package.SelectBoost.beta-blue.svg)](https://doi.org/10.32614/CRAN.package.SelectBoost.beta) -->
<!-- [![CRAN status](https://www.r-pkg.org/badges/version/SelectBoost.beta)](https://cran.r-project.org/package=SelectBoost.beta) -->
[![R-CMD-check](https://github.com/fbertran/SelectBoost.beta/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/fbertran/SelectBoost.beta/actions/workflows/R-CMD-check.yaml)
[![R-hub](https://github.com/fbertran/SelectBoost.beta/actions/workflows/rhub.yaml/badge.svg)](https://github.com/fbertran/SelectBoost.beta/actions/workflows/rhub.yaml)
<!-- badges: end -->


With the growth of big data, variable selection has become one of the major challenges in statistics. Although many methods have been proposed in the literature their performance in terms of recall and precision are limited in a context where the number of variables by far exceeds the number of observations or in a high correlated setting. 

Results: 

`SelectBoost.beta` brings the correlation-aware resampling strategy of the original SelectBoost package to **beta** regression by implementing an extension of the **SelectBoost** algorithm, F. Bertrand, I. Aouadi, N. Jung, R. Carapito, L. Vallat, S. Bahram, M. Maumy-Bertrand (2015) <https://doi.org/10.1093/bioinformatics/btaa855> and <https://doi.org/10.32614/CRAN.package.SelectBoost>.


It ships with:

- wrappers such as `betareg_step_aic()` and `betareg_glmnet()` that act as base
  selectors for beta-distributed outcomes, now including optional precision
  (phi) submodel search and observation weights;
- helper functions (`sb_normalize()`, `sb_group_variables()`,
  `sb_resample_groups()`, …) mirroring the core stages of SelectBoost; and
- the high-level `sb_beta()` driver that orchestrates normalisation,
  correlation analysis, grouped resampling and stability tallying in a single
  call.

## Choosing a selector

`SelectBoost.beta` ships with multiple selector families. Use the table below as a
starting point when deciding which helper best matches your workflow:

| Selector | What it does | Good defaults for | Extra packages |
| --- | --- | --- | --- |
| `betareg_step_aic()` / `betareg_step_bic()` / `betareg_step_aicc()` | Greedy stepwise search on `betareg` fits (mean submodel, optional phi search) using the chosen information criterion. | Small-to-moderate `p`, interpretable models, when you want to reuse `betareg` summaries. | `betareg` (installed automatically).
| `betareg_glmnet()` | Iteratively reweighted least squares with `glmnet` on the working responses; supports AIC/BIC/CV selection. | Higher-dimensional settings or when you need elastic-net regularisation with no extra dependencies. | `glmnet`.
| `betareg_lasso_gamlss()` | LASSO penalty through `gamlss::ri()` on the beta mean submodel. | Workflows already using `gamlss`, or when you need GAIC-tuned shrinkage. | `gamlss`, `gamlss.dist`.
| `betareg_enet_gamlss()` | Elastic-net variant via `gamlss.lasso::gnet()`. | When elastic-net is needed alongside GAMLSS diagnostics. | `gamlss`, `gamlss.dist`, `gamlss.lasso`.

All selectors expect complete cases for the supplied design matrix and only act
on the mean submodel. Offsets and observation-level weights beyond what is
exposed in each helper are currently unsupported.

Each resampling call returns per-group diagnostics (cached draws, observed
correlation summaries) and `sb_beta()` threads the same correlated surrogates
across all thresholds so cross-level comparisons remain aligned. Interval
responses are supported through the `interval` argument, which reuses the
`fastboost_interval()` logic directly inside `sb_beta()`.

The package is designed so that each stage of the workflow remains reusable on
its own. Users can plug in custom grouping strategies or selectors while still
benefiting from correlated resampling.



## Conference presentations

The SelectBoost4Beta approach was presented by Frédéric Bertrand and Myriam
Maumy at the Joint Statistical Meetings 2023 in Toronto ("Improving variable
selection in Beta regression models using correlated resampling") and at
BioC2023 in Boston ("SelectBoost4Beta: Improving variable selection in Beta
regression models"). Both communications highlighted how correlated resampling boosts
variable selection for Beta regression in high-dimensional, strongly correlated
settings.

## Installation

SelectBoost.beta is preparing for its first CRAN submission. Until it becomes
available there, install the development version from GitHub:

```{r, eval = FALSE}
devtools::install_github("fbertran/SelectBoost.beta")
```

Once the package lands on CRAN, the usual `install.packages("SelectBoost.beta")`
command will work as expected.

The selectors rely on the `betareg`, `glmnet`, and `gamlss` ecosystems. These
packages will be pulled in automatically when installing from source.

## Quick start

Simulate a correlated design, run the manual SelectBoost steps with
`betareg_step_aic()`, and compute selection frequencies:

```{r, cache=TRUE, eval=LOCAL}
library(SelectBoost.beta)
set.seed(42)

sim <- simulation_DATA.beta(n = 150, p = 6, s = 3, beta_size = c(1, -0.8, 0.6))
X_norm <- sb_normalize(sim$X)
corr_mat <- sb_compute_corr(X_norm)
groups <- sb_group_variables(corr_mat, c0 = 0.6)
resamples <- sb_resample_groups(X_norm, groups, B = 50)
coef_path <- sb_apply_selector_manual(X_norm, resamples, sim$Y, betareg_step_aic)
sel_freq <- sb_selection_frequency(coef_path, version = "glmnet")
sel_freq

attr(resamples, "diagnostics")
```

The `sb_beta()` wrapper performs the entire loop internally and returns a matrix
indexed by the correlation thresholds used during resampling:

```{r, cache=TRUE, eval=LOCAL}
sb <- sb_beta(sim$X, sim$Y, B = 50, step.num = 0.25,use.parallel = FALSE)
print(sb)
```

The result stores the selector used, the number of resamples, and the
correlation thresholds in its attributes. Dedicated methods make these easier to
inspect programmatically:

```{r, cache=TRUE, eval=LOCAL}
summary(sb)
if (requireNamespace("ggplot2", quietly = TRUE)) {
  autoplot.sb_beta(sb)
}
```

```{r, cache=TRUE, eval=LOCAL}
attr(sb, "selector")
attr(sb, "c0.seq")
attr(sb, "resample_diagnostics")[[1]]
```

### Understanding the `sb_beta()` output

The matrix returned by `sb_beta()` carries a number of attributes so downstream
code can recover how the stability frequencies were produced:

- `attr(sb, "c0.seq")` lists the absolute-correlation thresholds explored.
- `attr(sb, "steps.seq")` reports the raw sequence used to build that grid when
  `step.num` was provided.
- `attr(sb, "B")` records the number of correlated resamples per threshold.
- `attr(sb, "selector")` stores the selector name or expression.
- `attr(sb, "interval")` highlights whether interval resampling was used.
- `attr(sb, "resample_diagnostics")` holds per-threshold summaries of the
  cached surrogate draws.

These attributes mirror the original SelectBoost design and are documented in
`?sb_beta` to ease CRAN review.

```{r, cache=TRUE, eval=LOCAL}
single <- compare_selectors_single(sim$X, sim$Y, include_enet = TRUE)
```

`compare_selectors_single()` temporarily shortens column names so that the
selectors receive syntactically valid identifiers; the returned list remaps the
coefficients and long table back to the original labels.

```{r, cache=TRUE, eval=LOCAL}
freq <- suppressWarnings(compare_selectors_bootstrap(
  sim$X, sim$Y, B = 100, include_enet = TRUE, seed = 321
))
head(freq)
```

The `freq` column reports how often each variable was selected across the
bootstrap replicates. Values close to 1 indicate highly stable discoveries,
whereas small values suggest weak or noisy support. Increase `B` when you need
finer resolution; a few dozen resamples suffice for quick checks, while several
hundred deliver smoother estimates.

```{r, cache=TRUE, eval=LOCAL}
plot_compare_coeff(single$table)
```


```{r, cache=TRUE, eval=LOCAL}
plot_compare_freq(freq)
```

### Interval outcomes

`sb_beta()` can draw pseudo-responses from observed intervals by supplying
`Y_low`, `Y_high`, and an `interval` mode:

```{r, cache=TRUE, eval=LOCAL}
interval_fit <- sb_beta(
  sim$X,
  Y_low = pmax(sim$Y - 0.05, 0),
  Y_high = pmin(sim$Y + 0.05, 1),
  interval = "uniform",
  B = 30,
  step.num = 0.5
)
attr(interval_fit, "interval")
attr(interval_fit, "resample_diagnostics")
```
For a shortcut that always uses interval resampling, call
`sb_beta_interval(sim$X, Y_low, Y_high, sample = "uniform")`. The lower-level
`fastboost_interval()` helper remains available when you want to pair the
interval resampling logic with a custom selector outside `sb_beta()`.

### Response handling and squeezing

All selectors operate on responses in `(0, 1)`. By default `sb_beta()` and the
selector helpers squeeze the data away from the boundaries using the usual
SelectBoost transformation. Set `squeeze = FALSE` only if you have already
applied your own transformation; otherwise zero/one observations will trigger an
error.

### Parallel resampling

Setting `use.parallel = TRUE` instructs `sb_beta()` and `sb_resample_groups()` to
dispatch resamples and selector fits through
[`future.apply`](https://future.apply.futureverse.org/). Bring your own
`future::plan()` to select the desired backend (e.g. `multisession` on desktops):

```{r, eval = FALSE}
future::plan(future::multisession)
sb_parallel <- sb_beta(sim$X, sim$Y, B = 50, step.num = 0.25, use.parallel = TRUE)
future::plan(future::sequential)
```

Refer to the vignettes for a more detailed walk-through of the workflow and the
pseudo-code underpinning the algorithms. The new `Getting started with
SelectBoost.beta` vignette mirrors the CRAN submission example set by showing a
full run, interpreting the stability matrix, and comparing selectors side by
side.